{
    "data": [
        {
            "loss": 3.2786,
            "grad_norm": 2.2403953075408936,
            "learning_rate": 7.6e-05,
            "epoch": 1.18
        },
        {
            "loss": 2.6745,
            "grad_norm": 2.4197442531585693,
            "learning_rate": 0.00015600000000000002,
            "epoch": 2.35
        },
        {
            "loss": 2.2704,
            "grad_norm": 3.6515796184539795,
            "learning_rate": 0.00019810526315789474,
            "epoch": 3.53
        },
        {
            "loss": 1.9636,
            "grad_norm": 3.6491048336029053,
            "learning_rate": 0.00019389473684210527,
            "epoch": 4.71
        },
        {
            "loss": 1.6338,
            "grad_norm": 14.924678802490234,
            "learning_rate": 0.0001896842105263158,
            "epoch": 5.88
        },
        {
            "loss": 1.202,
            "grad_norm": 6.794827938079834,
            "learning_rate": 0.00018547368421052633,
            "epoch": 7.06
        },
        {
            "loss": 0.8849,
            "grad_norm": 6.914928436279297,
            "learning_rate": 0.00018126315789473684,
            "epoch": 8.24
        },
        {
            "loss": 0.6898,
            "grad_norm": 5.89191198348999,
            "learning_rate": 0.00017705263157894737,
            "epoch": 9.41
        },
        {
            "loss": 0.5485,
            "grad_norm": 8.947940826416016,
            "learning_rate": 0.0001728421052631579,
            "epoch": 10.59
        },
        {
            "loss": 0.4299,
            "grad_norm": 6.742187023162842,
            "learning_rate": 0.00016863157894736843,
            "epoch": 11.76
        },
        {
            "loss": 0.3776,
            "grad_norm": 6.584944725036621,
            "learning_rate": 0.00016442105263157896,
            "epoch": 12.94
        },
        {
            "loss": 0.3307,
            "grad_norm": 4.504278182983398,
            "learning_rate": 0.00016021052631578947,
            "epoch": 14.12
        },
        {
            "loss": 0.2952,
            "grad_norm": 4.552028656005859,
            "learning_rate": 0.00015600000000000002,
            "epoch": 15.29
        },
        {
            "loss": 0.2746,
            "grad_norm": 5.002443313598633,
            "learning_rate": 0.00015178947368421053,
            "epoch": 16.47
        },
        {
            "loss": 0.2537,
            "grad_norm": 3.806647777557373,
            "learning_rate": 0.00014757894736842106,
            "epoch": 17.65
        },
        {
            "loss": 0.2568,
            "grad_norm": 5.548525333404541,
            "learning_rate": 0.0001433684210526316,
            "epoch": 18.82
        },
        {
            "loss": 0.2393,
            "grad_norm": 4.045058250427246,
            "learning_rate": 0.00013915789473684212,
            "epoch": 20.0
        },
        {
            "loss": 0.2217,
            "grad_norm": 1.919187307357788,
            "learning_rate": 0.00013494736842105265,
            "epoch": 21.18
        },
        {
            "loss": 0.2457,
            "grad_norm": 4.063239574432373,
            "learning_rate": 0.00013073684210526316,
            "epoch": 22.35
        },
        {
            "loss": 0.2024,
            "grad_norm": 3.1671769618988037,
            "learning_rate": 0.0001265263157894737,
            "epoch": 23.53
        },
        {
            "loss": 0.2244,
            "grad_norm": 3.086515426635742,
            "learning_rate": 0.00012231578947368422,
            "epoch": 24.71
        },
        {
            "loss": 0.2166,
            "grad_norm": 2.7395503520965576,
            "learning_rate": 0.00011810526315789474,
            "epoch": 25.88
        },
        {
            "loss": 0.2149,
            "grad_norm": 2.7396206855773926,
            "learning_rate": 0.00011389473684210528,
            "epoch": 27.06
        },
        {
            "loss": 0.207,
            "grad_norm": 1.9898308515548706,
            "learning_rate": 0.00010968421052631578,
            "epoch": 28.24
        },
        {
            "loss": 0.2012,
            "grad_norm": 1.9410687685012817,
            "learning_rate": 0.00010547368421052633,
            "epoch": 29.41
        },
        {
            "loss": 0.2032,
            "grad_norm": 2.055018424987793,
            "learning_rate": 0.00010126315789473683,
            "epoch": 30.59
        },
        {
            "loss": 0.2033,
            "grad_norm": 0.7540998458862305,
            "learning_rate": 9.705263157894738e-05,
            "epoch": 31.76
        },
        {
            "loss": 0.2096,
            "grad_norm": 1.7092183828353882,
            "learning_rate": 9.28421052631579e-05,
            "epoch": 32.94
        },
        {
            "loss": 0.201,
            "grad_norm": 1.5260326862335205,
            "learning_rate": 8.863157894736842e-05,
            "epoch": 34.12
        },
        {
            "loss": 0.1873,
            "grad_norm": 0.49162557721138,
            "learning_rate": 8.442105263157896e-05,
            "epoch": 35.29
        },
        {
            "loss": 0.1975,
            "grad_norm": 1.1756705045700073,
            "learning_rate": 8.021052631578949e-05,
            "epoch": 36.47
        },
        {
            "loss": 0.1877,
            "grad_norm": 0.6968658566474915,
            "learning_rate": 7.6e-05,
            "epoch": 37.65
        },
        {
            "loss": 0.1889,
            "grad_norm": 0.6518814563751221,
            "learning_rate": 7.178947368421054e-05,
            "epoch": 38.82
        },
        {
            "loss": 0.1935,
            "grad_norm": 0.6411012411117554,
            "learning_rate": 6.757894736842105e-05,
            "epoch": 40.0
        },
        {
            "loss": 0.1898,
            "grad_norm": 0.612943172454834,
            "learning_rate": 6.336842105263158e-05,
            "epoch": 41.18
        },
        {
            "loss": 0.1856,
            "grad_norm": 0.6348641514778137,
            "learning_rate": 5.9157894736842114e-05,
            "epoch": 42.35
        },
        {
            "loss": 0.1847,
            "grad_norm": 0.6408896446228027,
            "learning_rate": 5.494736842105264e-05,
            "epoch": 43.53
        },
        {
            "loss": 0.1823,
            "grad_norm": 0.40014830231666565,
            "learning_rate": 5.073684210526316e-05,
            "epoch": 44.71
        },
        {
            "loss": 0.1899,
            "grad_norm": 0.6140313744544983,
            "learning_rate": 4.652631578947369e-05,
            "epoch": 45.88
        },
        {
            "loss": 0.1825,
            "grad_norm": 0.434142142534256,
            "learning_rate": 4.231578947368421e-05,
            "epoch": 47.06
        },
        {
            "loss": 0.1837,
            "grad_norm": 0.4548145830631256,
            "learning_rate": 3.8105263157894735e-05,
            "epoch": 48.24
        },
        {
            "loss": 0.1688,
            "grad_norm": 0.39834776520729065,
            "learning_rate": 3.389473684210526e-05,
            "epoch": 49.41
        },
        {
            "loss": 0.187,
            "grad_norm": 0.33021751046180725,
            "learning_rate": 2.968421052631579e-05,
            "epoch": 50.59
        },
        {
            "loss": 0.1841,
            "grad_norm": 0.5595523715019226,
            "learning_rate": 2.5473684210526315e-05,
            "epoch": 51.76
        },
        {
            "loss": 0.1792,
            "grad_norm": 0.5751563906669617,
            "learning_rate": 2.1263157894736842e-05,
            "epoch": 52.94
        },
        {
            "loss": 0.1767,
            "grad_norm": 0.5567391514778137,
            "learning_rate": 1.705263157894737e-05,
            "epoch": 54.12
        },
        {
            "loss": 0.1772,
            "grad_norm": 0.6215096116065979,
            "learning_rate": 1.2842105263157894e-05,
            "epoch": 55.29
        },
        {
            "loss": 0.1737,
            "grad_norm": 0.5520391464233398,
            "learning_rate": 8.631578947368422e-06,
            "epoch": 56.47
        },
        {
            "loss": 0.1841,
            "grad_norm": 0.3886842429637909,
            "learning_rate": 4.4210526315789476e-06,
            "epoch": 57.65
        },
        {
            "loss": 0.1813,
            "grad_norm": 0.5536352396011353,
            "learning_rate": 2.105263157894737e-07,
            "epoch": 58.82
        }
    ]
}